{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import random\n",
    "from collections import Counter\n",
    "#for text pre-processing\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "#for model-building\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "# bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#for word embedding\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim import corpora\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Data = pd.read_csv('/Users/hamza.ahmed/Python Apps/Data/Youtube_Knife_Reviews.csv')\n",
    "Data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "screen shot each video making grid\n",
    "methodology\n",
    "analysis\n",
    "brand mentions\n",
    "attributes\n",
    "features\n",
    "blade materials\n",
    "categories ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comment_Data = list(comment_words.lower() for comment_words in Data[\"Comment\"])\n",
    "#Tag_Data = list(tag_words.lower() for tag_words in Data[\"Video Tags\"])\n",
    "Transcribe_data = list(Transcribe_data.lower() for Transcribe_data in Data[\"Video Transcript\"])\n",
    "Description_data = list(Description_data.lower() for Description_data in Data[\"Video Description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Knife_Companies =['benchmade', 'crkt', 'kershaw', 'chris reeves', 'chris reeve', 'civivi', \"we knife\"]\n",
    "\n",
    "# Blade_Material=[\"AUS 4\" , \"AUS 8\", \"Bohler M390 \", \"Bohler N680 \", \"Bohler N690\" , \"M390\" , \"N680\" , \n",
    "#                 \"N690\" , \"Bohler\" , \"Böhler\",\"CPM 154\", \"CPM 20CV\" ,\"CPM 3V \" ,\"CPM CruWear \" , \n",
    "#                 \"CPM D2\", \"CPM M4\" ,\"CPM S30V\" ,\"CPM S35VN\" ,\"CPM S45VN\" ,\"CPM S90V\",\"CPM\"]\n",
    "\n",
    "# Handle Material=[\"aluminum\", \"brass\", \"carbon fiber\" , \"carbonfiber\" , \"forged carbon\", \"copper\", \"g10\", \"grivory\", \"micarta\", \"plastic\", \n",
    "      #\"stainless steel\", \"ss\" \"stainlesssteel\", \"Titanium\"]\n",
    "#Pivot_Assembly=[\"brass washer\" , \"BrassWasher\", \"Bronze washers\" , \"Bronzewashers\", \"Caged Ceramic\", \"Ball Bearing\", \"Caged Double\" ,\"Row Ceramic\", \"Caged Steel\", \"IKBS\", \"Phosphorous Bronze Washer\" , \"Phosphorous Bronze\", \"PhosphorousBronzeWasher\",\"Teflon Washer\"]\n",
    "#Blade_Types=[\"Alloy\", \"Carbon Steel\" , \"CarbonSteel\",\"D2\", \"Damasteel\", \"High Carbon\", \"HighCarbonStainlessSteel\", \"SS\", \"Stainless Steel\" , \"StainlessSteel\" , \"Stainless-Steel\"]\n",
    "\n",
    "#locking_mechanism = [\"Back Lock\",\"backlock\",\t\"Button Lock\",\"Buttonlock\",\"Deadbolt\", \"Double Detent\", \"Slip Joint\",\"Frame Lock\",\t\"Front Lock\",\"Frontlock\", \"Kinematic\"\t\"Liner Lock\",\t\"Linerlock\", \t\"Lock Back\",\t\"lockback\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#List=[\"aluminum\", \"brass\", \"carbon fiber\" , \"carbonfiber\" , \"forged carbon\", \"copper\", \"g10\", \"grivory\", \"micarta\", \"plastic\", \n",
    "      #\"stainless steel\", \"ss\" \"stainlesssteel\", \"Titanium\"]\n",
    "List = [\"AUS 4\" , \"AUS 8\", \"Bohler M390 \", \"Bohler N680 \", \"Bohler N690\" , \"M390\" , \"N680\" , \n",
    "\"N690\" , \"Bohler\" , \"Böhler\",\"CPM 154\", \"CPM 20CV\" ,\"CPM 3V \" ,\"CPM CruWear \" , \n",
    "\"CPM D2\", \"CPM M4\" ,\"CPM S30V\" ,\"CPM S35VN\" ,\"CPM S45VN\" ,\"CPM S90V\",\"CPM\",\"Damasteel\", \"High Carbon\", \n",
    "\"HighCarbonStainlessSteel\", \"SS\", \"Steel\",  \"Stainless Steel\" , \n",
    "\"StainlessSteel\" , \"Stainless-Steel\", \"Alloy\", \"Carbon Steel\" , \"CarbonSteel\",\"D2\"]\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "List = list(List.lower() for List in List)\n",
    "########\n",
    "#Tag Data\n",
    "#######\n",
    "#Vectorize the Data\n",
    "# vectForKnifeCompanies = CountVectorizer(vocabulary=Knife_Companies, ngram_range=(1, 2))\n",
    "# TD = vectForKnifeCompanies.fit_transform(Tag_Data)\n",
    "# TD = TD.toarray()\n",
    "# vectorizer_feature_names_Knife_Companies = vectForKnifeCompanies.get_feature_names_out()\n",
    "\n",
    "\n",
    "# #Arrange\n",
    "# Tag_Data = pd.DataFrame(data = TD, columns = vectorizer_feature_names_Knife_Companies)\n",
    "# Tag_Data_For_Knife_Companies = Tag_Data.rename(columns={col: col+'_in_Tags' for col in Tag_Data.columns})\n",
    "# print(Tag_Data_For_Knife_Companies)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vect = CountVectorizer(vocabulary=List, ngram_range=(1, 2))\n",
    "\n",
    "\n",
    "########\n",
    "#Description Data\n",
    "#######\n",
    "\n",
    "DD = vect.fit_transform(Description_data)\n",
    "DD = DD.toarray()\n",
    "vectorizer_feature_names = vect.get_feature_names_out()\n",
    "\n",
    "DescriptionData = pd.DataFrame(data = DD, columns = vectorizer_feature_names)\n",
    "Description_data_total = DescriptionData.rename(columns={col: col+'_in_Description' for col in DescriptionData.columns})\n",
    "#print(Description_data_For_Knife_Companies )\n",
    "\n",
    "\n",
    "########\n",
    "#Transcript Data\n",
    "#######\n",
    "\n",
    "\n",
    "TRD = vect.fit_transform(Transcribe_data)\n",
    "TRD = TRD.toarray()\n",
    "vectorizer_feature_names = vect.get_feature_names_out()\n",
    "\n",
    "TranscribeData = pd.DataFrame(data = TRD, columns = vectorizer_feature_names)\n",
    "TranscribeData_total  = TranscribeData.rename(columns={col: col+'_in_Transcript' for col in TranscribeData.columns})\n",
    "# print(TranscribeData_For_Knife_Companies)\n",
    "\n",
    "\n",
    "\n",
    "########\n",
    "#Comment Data\n",
    "#######\n",
    "\n",
    "\n",
    "CD = vect.fit_transform(Comment_Data)\n",
    "CD = CD.toarray()\n",
    "vectorizer_feature_names = vect.get_feature_names_out()\n",
    "\n",
    "\n",
    "CommentData = pd.DataFrame(data = CD, columns = vectorizer_feature_names)\n",
    "CommentData_total = CommentData.rename(columns={col: col+'_comments' for col in CommentData.columns})\n",
    "# print(CommentData_For_Knife_Companies)\n",
    "\n",
    "\n",
    "\n",
    "#Collecting it all!\n",
    "Youtube_Knife_Data = pd.ExcelWriter('Youtube_Knife_Data.xlsx')\n",
    "\n",
    "CommentData_total.to_excel(Youtube_Knife_Data, sheet_name='Comments')\n",
    "TranscribeData_total.to_excel(Youtube_Knife_Data, sheet_name='Transcribe')\n",
    "Description_data_total.to_excel(Youtube_Knife_Data, sheet_name='Description')\n",
    "\n",
    "Youtube_Knife_Data.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Knife Companies\n",
    "# Knife_Companies =['benchmade', 'crkt', 'kershaw', 'chris reeves', 'chris reeve', 'civivi', \"we knife\"]\n",
    "\n",
    "# ########\n",
    "# #Tag Data\n",
    "# #######\n",
    "# #Vectorize the Data\n",
    "# # vectForKnifeCompanies = CountVectorizer(vocabulary=Knife_Companies, ngram_range=(1, 2))\n",
    "# # TD = vectForKnifeCompanies.fit_transform(Tag_Data)\n",
    "# # TD = TD.toarray()\n",
    "# # vectorizer_feature_names_Knife_Companies = vectForKnifeCompanies.get_feature_names_out()\n",
    "\n",
    "\n",
    "# # #Arrange\n",
    "# # Tag_Data = pd.DataFrame(data = TD, columns = vectorizer_feature_names_Knife_Companies)\n",
    "# # Tag_Data_For_Knife_Companies = Tag_Data.rename(columns={col: col+'_in_Tags' for col in Tag_Data.columns})\n",
    "# # print(Tag_Data_For_Knife_Companies)\n",
    "\n",
    "\n",
    "\n",
    "# vectForKnifeCompanies = CountVectorizer(vocabulary=Knife_Companies, ngram_range=(1, 2))\n",
    "\n",
    "\n",
    "# ########\n",
    "# #Description Data\n",
    "# #######\n",
    "\n",
    "# DD = vectForKnifeCompanies.fit_transform(Description_data)\n",
    "# DD = DD.toarray()\n",
    "# vectorizer_feature_names_Knife_Companies = vectForKnifeCompanies.get_feature_names_out()\n",
    "\n",
    "# DescriptionData = pd.DataFrame(data = DD, columns = vectorizer_feature_names_Knife_Companies)\n",
    "# Description_data_For_Knife_Companies = DescriptionData.rename(columns={col: col+'_in_Description' for col in DescriptionData.columns})\n",
    "# #print(Description_data_For_Knife_Companies )\n",
    "\n",
    "\n",
    "# ########\n",
    "# #Transcript Data\n",
    "# #######\n",
    "\n",
    "\n",
    "# TRD = vectForKnifeCompanies.fit_transform(Transcribe_data)\n",
    "# TRD = TRD.toarray()\n",
    "# vectorizer_feature_names_Knife_Companies = vectForKnifeCompanies.get_feature_names_out()\n",
    "\n",
    "# TranscribeData = pd.DataFrame(data = TRD, columns = vectorizer_feature_names_Knife_Companies)\n",
    "# TranscribeData_For_Knife_Companies = TranscribeData.rename(columns={col: col+'_in_Transcript' for col in TranscribeData.columns})\n",
    "# # print(TranscribeData_For_Knife_Companies)\n",
    "\n",
    "\n",
    "\n",
    "# ########\n",
    "# #Comment Data\n",
    "# #######\n",
    "\n",
    "\n",
    "# CD = vectForKnifeCompanies.fit_transform(Comment_Data)\n",
    "# CD = CD.toarray()\n",
    "# vectorizer_feature_names_Knife_Companies = vectForKnifeCompanies.get_feature_names_out()\n",
    "\n",
    "\n",
    "# CommentData = pd.DataFrame(data = CD, columns = vectorizer_feature_names_Knife_Companies)\n",
    "# CommentData_For_Knife_Companies = CommentData.rename(columns={col: col+'_comments' for col in CommentData.columns})\n",
    "# # print(CommentData_For_Knife_Companies)\n",
    "\n",
    "\n",
    "\n",
    "# #Collecting it all!\n",
    "# All_Knife_Company_Mentions = pd.ExcelWriter('All_Knife_Company_Mentions.xlsx')\n",
    "# CommentData_For_Knife_Companies.to_excel(All_Knife_Company_Mentions, sheet_name='Comment Mentions')\n",
    "# TranscribeData_For_Knife_Companies.to_excel(All_Knife_Company_Mentions, sheet_name='Transcribe Mentions')\n",
    "# Description_data_For_Knife_Companies.to_excel(All_Knife_Company_Mentions, sheet_name='Description Mentions')\n",
    "\n",
    "# All_Knife_Company_Mentions.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "# doc_term_matrix = count_vect.fit_transform(Data[\"Video Transcript\"].values.astype('U'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_term_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "# LDA.fit(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     random_id = random.randint(0,len(count_vect.get_feature_names()))\n",
    "#     print(count_vect.get_feature_names()[random_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_topic = LDA.components_[0]\n",
    "# top_topic_words = first_topic.argsort()[-10:]\n",
    "# for i in top_topic_words:\n",
    "#     print(count_vect.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,topic in enumerate(LDA.components_):\n",
    "#     print(f'Top 10 words for topic #{i}:')\n",
    "#     print([count_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_values = LDA.transform(doc_term_matrix)\n",
    "# topic_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop = set(stopwords.words('english'))\n",
    "# exclude = set(string.punctuation)\n",
    "# lemma = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "# def clean(doc):\n",
    "#     stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "#     punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "#     normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "#     return normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_clean = [clean(doc).split() for doc in Data[\"Video Transcript\"]]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = Data['Video Transcript']\n",
    "# keywords = ('knife', 'Sharpness', 'Sharp')\n",
    "# if keywords in Data['Video Transcript']:\n",
    "#     print (keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #pd.DataFrame(zip(Data['Comment'],Data['Comment'].map(lambda d: re.escape(\"love\") in d)))\n",
    "# dictionary = corpora.Dictionary(doc_clean)\n",
    "# doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lda = gensim.models.ldamodel.LdaModel\n",
    "# ldamodel = Lda(doc_term_matrix, num_topics=50, id2word = dictionary, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ldamodel.print_topics(num_topics=5, num_words=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_list = ['poop']\n",
    "# comm=Data.Comment.str.lower().str.split('\\s')\n",
    "\n",
    "# sq=Data.assign(c=comm.apply(lambda x:[*{*x}&{*search_list}])\\\n",
    "# .str.join(','),d=comm.apply(lambda \\\n",
    "# x:[*{*x}&{*search_list}]).str.len())\n",
    "\n",
    "\n",
    "# # df1 = Data.Comment.str.split().apply(lambda x: Counter(x))\n",
    "# # df1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
