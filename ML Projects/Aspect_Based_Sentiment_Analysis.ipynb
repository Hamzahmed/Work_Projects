{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanza.download('en')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beatles_Paragraph = \"Sgt. Pepperâ€™s applied the concept of the symphony to rock and roll, adding an incredible (and soon overused) dimension to rock and roll. Nothing could have been more ambitious than the current release: The Beatles is the history and synthesis of Western music. And that, of course is what rock and roll is, and that is what the Beatles are. Rock and roll, the first successful art form of the McLuhan age, is a series of increasing hybrids of musical styles, starting from its basic hybrid of country and western music and black American music (blues, if you will). That merger represents the distantly effected marriage of the music of England and Africa, a yin and yang that could be infinitely extended.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beatles_p1 = nlp(Beatles_Paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_doc_info(doc):\n",
    "    print(f\"Num sentences:\\t{len(doc.sentences)}\")\n",
    "    print(f\"Num tokens:\\t{doc.num_tokens}\")\n",
    "    print(f\"Num words:\\t{doc.num_words}\")\n",
    "    print(f\"Num entities:\\t{len(doc.entities)}\")\n",
    "    \n",
    "def print_sentence_info(sentence):\n",
    "    print(f\"Text: {sentence.text}\")\n",
    "    print(f\"Num tokens:\\t{len(sentence.tokens)}\")\n",
    "    print(f\"Num words:\\t{len(sentence.words)}\")\n",
    "    print(f\"Num entities:\\t{len(sentence.entities)}\")\n",
    "\n",
    "def print_token_info(token):\n",
    "    print(f\"Text:\\t{token.text}\")\n",
    "    print(f\"Start:\\t{token.start_char}\")\n",
    "    print(f\"End:\\t{token.end_char}\")\n",
    "    \n",
    "def print_word_info(word):\n",
    "    print(f\"Text:\\t{word.text}\")\n",
    "    print(f\"Lemma: \\t{word.lemma}\")\n",
    "    print(f\"UPOS: \\t{word.upos}\")\n",
    "    print(f\"XPOS: \\t{word.xpos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_doc_info(beatles_p1)\n",
    "# print_sentence_info(beatles_p1.sentences[0])\n",
    "# print_token_info(beatles_p1.sentences[0].tokens[2])\n",
    "print_word_info(beatles_p1.sentences[1].words[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_info_df(doc):\n",
    "    \"\"\"\n",
    "    - Parameters: doc (a Stanza Document object)\n",
    "    - Returns: A Pandas DataFrame object with one row for each token in\n",
    "      doc, and columns for text, lemma, upos, and xpos.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for sentence in doc.sentences:\n",
    "        for word in sentence.words:\n",
    "            row = {\n",
    "                \"text\": word.text,\n",
    "                \"lemma\": word.lemma,\n",
    "                \"upos\": word.upos,\n",
    "                \"xpos\": word.xpos,\n",
    "            }\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "word_info_df(beatles_p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_entity_info(entity):\n",
    "    print(f\"Text:\\t{entity.text}\")\n",
    "    print(f\"Type:\\t{entity.type}\")\n",
    "    print(f\"Start:\\t{entity.start_char}\")\n",
    "    print(f\"End:\\t{entity.end_char}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_entity_info(beatles_p1.entities[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_descriptor(sentence):\n",
    "    \"\"\"\n",
    "    - Parameters: sentence (a Stanza Sentence object)\n",
    "    - Returns: A string descriptor for the sentiment value of sentence.\n",
    "    \"\"\"\n",
    "    sentiment_value = sentence.sentiment\n",
    "    if (sentiment_value == 0):\n",
    "        return \"negative\"\n",
    "    elif (sentiment_value == 1):\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return \"positive\"\n",
    "\n",
    "print(sentiment_descriptor(beatles_p1.sentences[0]))\n",
    "\n",
    "# neutral\n",
    "\n",
    "def sentence_sentiment_df(doc):\n",
    "    \"\"\"\n",
    "    - Parameters: doc (a Stanza Document object)\n",
    "    - Returns: A Pandas DataFrame with one row for each sentence in doc,\n",
    "      and columns for the sentence text and sentiment descriptor.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for sentence in doc.sentences:\n",
    "        row = {\n",
    "            \"text\": sentence.text,\n",
    "            \"sentiment\": sentiment_descriptor(sentence)\n",
    "        }\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_sentiment_df(beatles_p1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_doc(file_path):\n",
    "    with open(file_path) as f:\n",
    "        txt = f.read()\n",
    "    return txt\n",
    "\n",
    "Beatles_PATH = \"/Users/hamza.ahmed/Python Apps/ML Projects/beatles.txt\"\n",
    "Beatles_text = load_text_doc(Beatles_PATH)\n",
    "Beatles = nlp(Beatles_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_person_entities(doc):\n",
    "    return [ent for ent in doc.entities if ent.type == \"PERSON\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def person_df(doc):\n",
    "    \"\"\"\n",
    "    - Parameters: doc (a Stanza Document object)\n",
    "    - Returns: A Pandas DataFrame with one row for each entity in doc\n",
    "      that has a \"PERSON\" type, and and columns text, type, start_char, \n",
    "      and the sentiment of the sentence in which the entity appears.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    persons = select_person_entities(doc)\n",
    "    for person in persons:\n",
    "        row = {\n",
    "            \"text\": person.text,\n",
    "            \"type\": person.type,\n",
    "            \"start_char\": person.start_char,\n",
    "            \"end_char\": person.end_char,\n",
    "            \"sentence_sentiment\": sentiment_descriptor(person._sent)\n",
    "        }\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "characters = person_df(Beatles)\n",
    "display(characters.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_unique_items(df, col):\n",
    "    return len(df[col].unique())\n",
    "\n",
    "num_unique_items(characters, \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_count(df, col, limit=10):\n",
    "    return df[col].value_counts().head(limit)\n",
    "\n",
    "frequency_count(characters, \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_descriptor_to_val(descriptor):\n",
    "    \"\"\"\n",
    "    - Parameters: descriptor (\"negative\", \"neutral\", or \"positive\")\n",
    "    - Returns: -1 for \"negative\", 0 for \"neutral\", 1 for \"positive\"\n",
    "    \"\"\"\n",
    "    if descriptor == \"negative\":\n",
    "        return -1\n",
    "    elif descriptor == \"neutral\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def character_sentiment(df):\n",
    "    \"\"\"\n",
    "    - Parameters: df (Pandas DataFrame)\n",
    "    - df must contain \"text\" and \"sentiment_descriptor\" columns.\n",
    "    - Returns: \n",
    "    \"\"\"\n",
    "    sentiment = df.copy()\n",
    "    sentiment[\"sentence_sentiment\"] = [\n",
    "        sentiment_descriptor_to_val(s) for s\n",
    "        in sentiment[\"sentence_sentiment\"]\n",
    "    ]\n",
    "    sentiment = sentiment[[\"text\", \"sentence_sentiment\"]]\n",
    "    sentiment = sentiment.groupby(\"text\").sum().reset_index()\n",
    "    \n",
    "    return sentiment.sort_values(\"sentence_sentiment\")\n",
    "\n",
    "sentiment_df = character_sentiment(characters)\n",
    "\n",
    "print(\"Characters in the most negative settings.\")\n",
    "display(sentiment_df.head(5))\n",
    "\n",
    "print(\"Characters in the most positive settings\")\n",
    "display(sentiment_df.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
