{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from create_database import create_database\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "from psycopg2 import sql\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import geoalchemy2\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_params = {\n",
    "    'user': os.environ.get('POSTGRES_USER'),\n",
    "    'password': os.environ.get('POSTGRES_PASSWORD', ''),\n",
    "    'host': 'localhost',\n",
    "    'port': os.environ.get('POSTGRES_PORT', '')\n",
    "}\n",
    "conn_params\n",
    "# create_database(conn_params,'threatanalysis', 'postgis')\n",
    "\n",
    "conn = psycopg2.connect(dbname='threatanalysis', **conn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import psycopg2\n",
    "# from psycopg2 import sql\n",
    "\n",
    "# try:\n",
    "#     # Database creation and extension setup\n",
    "#     dbname = 'threatanalysis'\n",
    "#     new_db_name = sql.Identifier(dbname)\n",
    "\n",
    "#     # Wrap the connection setup in a 'with' statement\n",
    "#     with psycopg2.connect(**conn_params) as conn:\n",
    "#         with conn.cursor() as cursor:\n",
    "#             try:\n",
    "#                 # Set autocommit to True before creating the database\n",
    "#                 conn.autocommit = True\n",
    "#                 # Create the database if it doesn't exist\n",
    "#                 cursor.execute(sql.SQL(\"CREATE DATABASE {}\").format(new_db_name))\n",
    "#                 # Reset autocommit to False after creating the database\n",
    "#                 conn.autocommit = False\n",
    "#                 # Switch to the new database\n",
    "#                 conn = psycopg2.connect(database=dbname, **conn_params)\n",
    "#                 cursor = conn.cursor()\n",
    "#                 # Enable the PostGIS extension\n",
    "#                 cursor.execute(sql.SQL('CREATE EXTENSION IF NOT EXISTS postgis;'))\n",
    "#                 print(f\"Database '{dbname}' created successfully.\")\n",
    "#             except psycopg2.Error as e:\n",
    "#                 print(f\"Error creating database '{dbname}': {e}\")\n",
    "# except psycopg2.Error as e:\n",
    "#     print(f\"Error connecting to the default database: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_gdf = gpd.read_file('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json')\n",
    "county_gdf.columns = county_gdf.columns.str.lower()\n",
    "county_gdf = (county_gdf[['name', 'geometry']]\n",
    ".copy()\n",
    ".rename(columns={'name': 'event_county'})\n",
    ")\n",
    "county_gdf['event_county'] = county_gdf['event_county'].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('https://raw.githubusercontent.com/nonviolent-action-lab/crowd-counting-consortium/master/ccc_compiled_2021-present.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf.head(10)\n",
    "# len(gdf)\n",
    "# gdf.columns\n",
    "# gdf.dtypes\n",
    "# # county_gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['lat'] = pd.to_numeric(gdf['lat'], errors='coerce')\n",
    "gdf['lon'] = pd.to_numeric(gdf['lon'], errors='coerce')\n",
    "\n",
    "from shapely.geometry import Point\n",
    "geometry = [Point(lon, lat) for lon, lat in zip(gdf['lon'], gdf['lat'])]\n",
    "gdf = gpd.GeoDataFrame(gdf, geometry=geometry, crs=gdf.crs)\n",
    "gdf = gdf.replace('NA', None)\n",
    "# # gdf = gpd.GeoDataFrame(gdf, geometry=gpd.points_from_xy(gdf.lon, gdf.lat))\n",
    "\n",
    "# gdf[gdf.duplicated(subset='fips_code', keep=False)]\n",
    "# # Convert the 'dates' column to datetime format\n",
    "gdf['date'] = pd.to_datetime(gdf['date'])\n",
    "gdf_2021 = gdf[gdf['date'].dt.year == 2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_join = pd.join(gdf_2021, county_gdf, on='key', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sjoined_data = gpd.sjoin(gdf_2021,county_gdf, predicate='within', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sjoined_data['source'] = sjoined_data.apply(lambda row: ','.join(str(val) for val in row.filter(like='source_') if val is not None), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Threat Analysis Project/ETL_Service/data_engineer_tech_challenge_existing_dataset.geojson'\n",
    "ex_data = gpd.read_file(file_path)\n",
    "# gdf.head()\n",
    "# # len(gdf)\n",
    "# gdf.dtypes\n",
    "ex_data = ex_data.drop(columns = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex_data.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex_data[ex_data.duplicated('geometry')].sort_values(by='event_state', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = gpd.GeoDataFrame({'event_id': sjoined_data['fips_code']\n",
    "                                  ,'event_date':sjoined_data['date']\n",
    "                                   ,'event_state':sjoined_data['state']\n",
    "                                    ,'event_county':sjoined_data['event_county']\n",
    "                                     ,'event_city':sjoined_data['locality']\n",
    "                                      ,'event_type':sjoined_data['type']\n",
    "                                       ,'event_source':sjoined_data['source']\n",
    "                                       ,'geometry':sjoined_data['geometry']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = new_data.groupby(['event_id', 'event_date', 'geometry']).agg({\n",
    "    'event_state': 'first',\n",
    "    'event_county': 'first',\n",
    "    'event_city': 'first',\n",
    "    'event_type': lambda x: '; '.join(x) if any(x) else None,\n",
    "    'event_source': lambda x: '; '.join(x) if any(x) else None\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SQL query to fetch data from the table\n",
    "table_name = \"eventdata\"\n",
    "sql_query = f\"\"\"SELECT * FROM {table_name};\"\"\"\n",
    "\n",
    "# Use Pandas to read the query result into a DataFrame\n",
    "EventData = gpd.read_postgis(sql_query, conn, geom_col='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EventData = gpd.read_postgis(sql_query, conn, geom_col='geometry')\n",
    "\n",
    "max_row_event = max(EventData['event_id'])\n",
    "max_row_id = max(EventData['id'])\n",
    "\n",
    "max_row_event = max_row_event + 1\n",
    "max_row_id = max_row_id +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a new range of IDs starting from max_row\n",
    "new_event_ids = range(max_row_event, max_row_event + len(grouped_data))\n",
    "# Generate a new range of IDs starting from max_row\n",
    "new_ids = range(max_row_id, max_row_id + len(grouped_data))\n",
    "\n",
    "# Assign the new IDs to the 'event_id' column\n",
    "grouped_data['event_id'] = new_event_ids\n",
    "grouped_data['id'] = new_event_ids\n",
    "\n",
    "grouped_data = gpd.GeoDataFrame(grouped_data)\n",
    "\n",
    "desired_crs = 'EPSG:4326'\n",
    "\n",
    "# Set the CRS for the GeoDataFrame\n",
    "grouped_data.set_crs(desired_crs, allow_override=True)\n",
    "\n",
    "# Display the updated grouped_data\n",
    "grouped_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname = 'threatanalysis'\n",
    "engine = create_engine(f\"postgresql+psycopg2://{conn_params['user']}:{conn_params['password']}@{conn_params['host']}:{conn_params['port']}/{dbname}\")\n",
    "engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EventData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_crs = 'EPSG:4326'\n",
    "\n",
    "# Set the CRS for the GeoDataFrame\n",
    "grouped_data = grouped_data.set_crs(desired_crs, allow_override=True)\n",
    "grouped_data.to_postgis(table_name, engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([ex_data, new_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sjoined_data[sjoined_data.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GeoAlchemy engine\n",
    "engine = create_engine(f\"postgresql+psycopg2://{conn_params['user']}:{conn_params['password']}@{conn_params['host']}:{conn_params['port']}/{dbname}\")\n",
    "\n",
    "# Assuming 'gdf' is your GeoPandas DataFrame\n",
    "table_name = 'eventdata'  # Replace with your desired table name\n",
    "\n",
    "# Use GeoAlchemy to create a table with geometry column\n",
    "existing_data.to_postgis(table_name, engine, if_exists='replace', index=True, index_label='id')\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GeoAlchemy engine\n",
    "engine = create_engine(f\"postgresql+psycopg2://{conn_params['user']}:{conn_params['password']}@{conn_params['host']}:{conn_params['port']}/{dbname}\")\n",
    "\n",
    "# Assuming 'gdf' is your GeoPandas DataFrame\n",
    "table_name = 'countydata'  # Replace with your desired table name\n",
    "\n",
    "# Use GeoAlchemy to create a table with geometry column\n",
    "county_gdf.to_postgis(table_name, engine, if_exists='replace', index=True, index_label='id')\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "# # Create a Spark session\n",
    "# spark = SparkSession.builder.appName(\"actionlabdataretrieal\").getOrCreate()\n",
    "\n",
    "# # URL to retrieve data from\n",
    "# url = \"https://raw.githubusercontent.com/nonviolent-action-lab/crowd-counting-consortium/master/ccc_compiled_2021-present.csv\"\n",
    "\n",
    "# # Read data from the URL into a DataFrame\n",
    "# df = spark.read.csv(url, header=True, inferSchema=True)\n",
    "\n",
    "# # Show the DataFrame\n",
    "# df.show(10)\n",
    "\n",
    "# # Perform further data processing or analysis as needed\n",
    "\n",
    "# # Stop the Spark session\n",
    "# spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a9dcb4b3896803ced2b95129df76f553611a6bd31fc1b527c81769ce2760891"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
